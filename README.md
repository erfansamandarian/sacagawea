# sacagawea

## process

youtube video : autogenerated captions, autogenerated translation

speech recognition : https://github.com/alphacep/vosk-api (doesn't support hebrew)

text-to-speech : ms-edge or local on device https://github.com/coqui-ai/TTS

## flow

### option a (default)

youtube video (with captions) -> google translate api -> ms-edge or local text-to-speech

### option b (more room for error)

youtube video (without captions) -> speech recognition -> google translate api -> ms-edge or local text-to-speech

### option c (ideal but hardware / api limitations)

live audio capture -> speech recognition -> google translate api -> ms-edge or local text-to-speech

potential issue: i don't think this stack is fast enough / even feasible to enable this process on the fly
